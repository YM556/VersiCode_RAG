"""
Clear the<start>and<end>generated by the model in inference
"""

import json
import os
import sys

model_name = 'Llama-3-70b-chat-hf'

# result_path =  f'/Users/qingyuanzii/Desktop/Versi-Code-Gen/VerisiCode-RAG/Generation/output/library_source_code/withoutRAG/line/meta-llama/Llama-3-70b-chat-hf/library_source_code_line.json' #改 token,line,block
result_path = './line/meta-llama/Llama-3-70b-chat-hf/stackoverflow_line.json'
# result_path = "/Users/qingyuanzii/Desktop/Versi-Code-Gen/VerisiCode-RAG/Generation/together_ai/tmp/meta-llama/Llama-3-70b-chat-hf/stackoverflow_block.json"

with open(result_path, 'r', encoding='utf-8')as fr:
    lodict = json.load(fr)
data_dict = lodict
data_list = data_dict['data']

for data in data_list[:200]:
    temp_list = []
    model_output_list = eval(data['model_output'])  #改
    for output in model_output_list:
        if "<start>" in output and "<end>" in output:
            start_index = output.find("<start>") + len("<start>")
            end_index = output.find("<end>")
            content = output[start_index:end_index].replace('```python', '').replace('```', '')
        else:
            content = "no_answer"

        temp_list.append(content)

    data['model_output_token_clear'] = str(temp_list)   #change token,line,block

with open(result_path, 'w', encoding='utf-8')as fw:
    json.dump(data_dict, fw, indent=4, ensure_ascii=False)